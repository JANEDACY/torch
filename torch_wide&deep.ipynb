{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5060822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4.81k/4.81k [01:44<00:00, 46.0KB/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "\n",
    "# 加载MovieLens数据\n",
    "data = movielens.load_pandas_df(\n",
    "    size=\"100k\",\n",
    "    header=[\"userID\", \"itemID\", \"rating\"],\n",
    "    genres_col=\"genre\"\n",
    ")\n",
    "\n",
    "# 将电影类型编码为多热向量\n",
    "genres_encoder = MultiLabelBinarizer()\n",
    "data[\"genre\"] = genres_encoder.fit_transform(\n",
    "    data[\"genre\"].apply(lambda s: s.split(\"|\"))\n",
    ").tolist()\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train, test = python_random_split(data, ratio=0.75, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e130dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class WideAndDeepModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, genre_dim, embedding_dim, hidden_units):\n",
    "        super(WideAndDeepModel, self).__init__()\n",
    "        \n",
    "        # Embedding 层\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)  # 用户 ID 的 embedding\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)  # 物品 ID 的 embedding\n",
    "        \n",
    "        # Wide 部分\n",
    "        self.wide = nn.Linear(embedding_dim * 2, 1)  # Wide 部分的输入为用户和物品的 embedding 拼接\n",
    "        \n",
    "        # Deep 部分\n",
    "        self.deep = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2 + genre_dim, hidden_units[0]),  # Deep 部分的输入包括用户 embedding，物品 embedding 和类型特征\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[1], 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, genre_features):\n",
    "        # 获取用户和物品的 embedding\n",
    "        user_embedded = self.user_embedding(user_ids)  # 输出形状：[batch_size, embedding_dim]\n",
    "        item_embedded = self.item_embedding(item_ids)  # 输出形状：[batch_size, embedding_dim]\n",
    "        \n",
    "        # Wide 部分\n",
    "        wide_input = torch.cat([user_embedded, item_embedded], dim=1)  # 拼接用户和物品的 embedding\n",
    "        wide_output = self.wide(wide_input)\n",
    "        \n",
    "        # Deep 部分\n",
    "        deep_input = torch.cat([user_embedded, item_embedded, genre_features], dim=1)  # 拼接所有特征\n",
    "        deep_output = self.deep(deep_input)\n",
    "        \n",
    "        # 合并 Wide 和 Deep 部分\n",
    "        return wide_output + deep_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05b9e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        user_id = torch.tensor(row[\"userID\"], dtype=torch.long)  # 用户 ID（索引）\n",
    "        item_id = torch.tensor(row[\"itemID\"], dtype=torch.long)  # 物品 ID（索引）\n",
    "        genre_features = torch.tensor(row[\"genre\"], dtype=torch.float32)  # 电影类型特征\n",
    "        rating = torch.tensor(row[\"rating\"], dtype=torch.float32)  # 评分\n",
    "        return user_id, item_id, genre_features, rating\n",
    "\n",
    "train_dataset = MovieLensDataset(train)\n",
    "test_dataset = MovieLensDataset(test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04e57dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ana\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_ids, item_ids, genre_features, ratings \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenre_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, ratings)\n\u001b[0;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mD:\\ana\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[19], line 26\u001b[0m, in \u001b[0;36mWideAndDeepModel.forward\u001b[1;34m(self, user_ids, item_ids, genre_features)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_ids, item_ids, genre_features):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# 获取用户和物品的 embedding\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     user_embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 输出形状：[batch_size, embedding_dim]\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     item_embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embedding(item_ids)  \u001b[38;5;66;03m# 输出形状：[batch_size, embedding_dim]\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Wide 部分\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ana\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\ana\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\ana\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2195\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# 初始化模型\n",
    "num_users = data[\"userID\"].nunique()  # 用户总数\n",
    "num_items = data[\"itemID\"].nunique()  # 物品（电影）总数\n",
    "genre_dim = 19  # 类型特征的维度\n",
    "embedding_dim = 8  # Embedding 向量的维度\n",
    "hidden_units = [64, 32]  # Deep 部分的隐藏层单元数\n",
    "\n",
    "model = WideAndDeepModel(\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    genre_dim=genre_dim,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_units=hidden_units\n",
    ")\n",
    "# 训练模型\n",
    "\n",
    "num_epochs = 20\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for user_ids, item_ids, genre_features, ratings in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_ids, item_ids, genre_features)\n",
    "        loss = criterion(outputs, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae51c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"计算 RMSE（均方根误差）\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    \"\"\"计算 MAE（平均绝对误差）\"\"\"\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def calculate_ndcg(y_true, y_pred, k=10):\n",
    "    \"\"\"计算 NDCG@K（归一化折损累积增益）\"\"\"\n",
    "    def dcg_score(y_true, y_pred, k):\n",
    "        order = np.argsort(y_pred)[::-1]\n",
    "        y_true = np.take(y_true, order[:k])\n",
    "        gain = 2 ** y_true - 1\n",
    "        discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "        return np.sum(gain / discounts)\n",
    "    \n",
    "    dcg = dcg_score(y_true, y_pred, k)\n",
    "    idcg = dcg_score(y_true, y_true, k)\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def calculate_precision_at_k(y_true, y_pred, k=10):\n",
    "    \"\"\"计算 Precision@K\"\"\"\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    return np.sum(y_true) / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc5121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集上的 RMSE: 1.1008\n",
      "测试集上的 MAE: 0.9041\n",
      "测试集上的 NDCG@10: 0.4188\n",
      "测试集上的 Precision@10: 3.6000\n",
      "为用户196推荐的电影:\n",
      "电影ID: 214, 预测评分: 4.19\n",
      "电影ID: 51, 预测评分: 4.15\n",
      "电影ID: 286, 预测评分: 4.12\n",
      "电影ID: 483, 预测评分: 4.11\n",
      "电影ID: 299, 预测评分: 4.10\n",
      "电影ID: 89, 预测评分: 4.08\n",
      "电影ID: 484, 预测评分: 4.08\n",
      "电影ID: 133, 预测评分: 4.07\n",
      "电影ID: 302, 预测评分: 4.07\n",
      "电影ID: 549, 预测评分: 4.06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 测试集评估\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_features, item_features, genre_features, ratings in test_loader:\n",
    "        outputs = model(user_features, item_features, genre_features)\n",
    "        y_true.extend(ratings.squeeze().tolist())\n",
    "        y_pred.extend(outputs.squeeze().tolist())\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "rmse = calculate_rmse(y_true, y_pred)\n",
    "mae = calculate_mae(y_true, y_pred)\n",
    "ndcg = calculate_ndcg(y_true, y_pred, k=10)\n",
    "precision_at_k = calculate_precision_at_k(y_true, y_pred, k=10)\n",
    "\n",
    "print(f\"测试集上的 RMSE: {rmse:.4f}\")\n",
    "print(f\"测试集上的 MAE: {mae:.4f}\")\n",
    "print(f\"测试集上的 NDCG@10: {ndcg:.4f}\")\n",
    "print(f\"测试集上的 Precision@10: {precision_at_k:.4f}\")\n",
    "\n",
    "# 推荐电影\n",
    "recommendations = recommend_movies(196, top_k=10)\n",
    "print(\"为用户196推荐的电影:\")\n",
    "for movie, rating in recommendations:\n",
    "    print(f\"电影ID: {movie}, 预测评分: {rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82a77b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为用户196推荐的电影:\n",
      "电影ID: 1366, 预测评分: 4.96\n",
      "电影ID: 1065, 预测评分: 4.88\n",
      "电影ID: 1313, 预测评分: 4.82\n",
      "电影ID: 1294, 预测评分: 4.78\n",
      "电影ID: 1232, 预测评分: 4.78\n",
      "电影ID: 1307, 预测评分: 4.77\n",
      "电影ID: 1201, 预测评分: 4.76\n",
      "电影ID: 1318, 预测评分: 4.75\n",
      "电影ID: 1184, 预测评分: 4.75\n",
      "电影ID: 1212, 预测评分: 4.74\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies(user_id, top_k=10):\n",
    "    # 获取所有电影ID\n",
    "    all_movies = data[\"itemID\"].unique()\n",
    "    \n",
    "    # 构造用户-电影对\n",
    "    user_features = torch.tensor([[user_id]], dtype=torch.float32).repeat(len(all_movies), 1)\n",
    "    item_features = torch.tensor(all_movies, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    # 获取所有电影的 genre 特征\n",
    "    genre_features = torch.tensor(\n",
    "        data[data[\"itemID\"].isin(all_movies)][\"genre\"].tolist(), \n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    \n",
    "    # 确保 genre_features 的形状与 user_features 和 item_features 匹配\n",
    "    if genre_features.shape[0] != len(all_movies):\n",
    "        # 如果 genre_features 的长度不匹配，可能需要重新获取 genre 特征\n",
    "        genre_features = torch.tensor(\n",
    "            [data[data[\"itemID\"] == movie][\"genre\"].values[0] for movie in all_movies],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "    \n",
    "    # 使用模型预测评分\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_features, item_features, genre_features)\n",
    "    \n",
    "    # 将预测结果与电影ID配对并排序\n",
    "    movie_ratings = list(zip(all_movies, predictions.squeeze().tolist()))\n",
    "    top_movies = sorted(movie_ratings, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    return top_movies\n",
    "# 为用户196推荐10部电影\n",
    "recommendations = recommend_movies(196, top_k=10)\n",
    "print(\"为用户196推荐的电影:\")\n",
    "for movie, rating in recommendations:\n",
    "    print(f\"电影ID: {movie}, 预测评分: {rating:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207d63a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
