{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5060822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4.81k/4.81k [00:02<00:00, 1.94kKB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影类型: ['Action' 'Adventure' 'Animation' \"Children's\" 'Comedy' 'Crime'\n",
      " 'Documentary' 'Drama' 'Fantasy' 'Film-Noir' 'Horror' 'Musical' 'Mystery'\n",
      " 'Romance' 'Sci-Fi' 'Thriller' 'War' 'Western' 'unknown']\n",
      "   userID  itemID  rating                                              genre\n",
      "0     196     242     3.0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "1     186     302     3.0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, ...\n",
      "2      22     377     1.0  [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "3     244      51     2.0  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, ...\n",
      "4     166     346     1.0  [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "75000 条训练样本和 25000 条测试样本\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from recommenders.datasets import movielens\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "\n",
    "# 加载MovieLens数据\n",
    "data = movielens.load_pandas_df(\n",
    "    size=\"100k\",\n",
    "    header=[\"userID\", \"itemID\", \"rating\"],\n",
    "    genres_col=\"genre\"\n",
    ")\n",
    "\n",
    "# 将电影类型编码为多热向量\n",
    "genres_encoder = MultiLabelBinarizer()\n",
    "data[\"genre\"] = genres_encoder.fit_transform(\n",
    "    data[\"genre\"].apply(lambda s: s.split(\"|\"))\n",
    ").tolist()\n",
    "\n",
    "# 打印电影类型\n",
    "print(\"电影类型:\", genres_encoder.classes_)\n",
    "print(data.head())\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train, test = python_random_split(data, ratio=0.75, seed=42)\n",
    "print(f\"{len(train)} 条训练样本和 {len(test)} 条测试样本\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e130dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class WideAndDeepModel(nn.Module):\n",
    "    def __init__(self, user_dim, item_dim, num_genres, hidden_units):\n",
    "        super(WideAndDeepModel, self).__init__()\n",
    "        \n",
    "        # Wide部分：交叉特征\n",
    "        self.user_embedding_wide = nn.Embedding(num_embeddings=1000, embedding_dim=1)\n",
    "        self.item_embedding_wide = nn.Embedding(num_embeddings=2000, embedding_dim=1)\n",
    "        \n",
    "        # Deep部分：嵌入层和全连接层\n",
    "        self.user_embedding_deep = nn.Embedding(num_embeddings=1000, embedding_dim=user_dim)\n",
    "        self.item_embedding_deep = nn.Embedding(num_embeddings=2000, embedding_dim=item_dim)\n",
    "        self.genre_embedding = nn.Linear(num_genres, item_dim)\n",
    "        \n",
    "        self.deep = nn.Sequential(\n",
    "            nn.Linear(user_dim + item_dim * 2, hidden_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[1], 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, genres):\n",
    "        # Wide部分\n",
    "        user_emb_wide = self.user_embedding_wide(user_ids).squeeze()\n",
    "        item_emb_wide = self.item_embedding_wide(item_ids).squeeze()\n",
    "        wide_input = user_emb_wide + item_emb_wide\n",
    "        \n",
    "        # Deep部分\n",
    "        user_emb_deep = self.user_embedding_deep(user_ids)\n",
    "        item_emb_deep = self.item_embedding_deep(item_ids)\n",
    "        genre_emb = self.genre_embedding(genres)\n",
    "        \n",
    "        deep_input = torch.cat([user_emb_deep, item_emb_deep, genre_emb], dim=-1)\n",
    "        deep_output = self.deep(deep_input)\n",
    "        \n",
    "        # 合并Wide和Deep部分\n",
    "        output = wide_input + deep_output.squeeze()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b9e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        user_id = torch.tensor(row[\"userID\"], dtype=torch.long)\n",
    "        item_id = torch.tensor(row[\"itemID\"], dtype=torch.long)\n",
    "        genre = torch.tensor(row[\"genre\"], dtype=torch.float)\n",
    "        rating = torch.tensor(row[\"rating\"], dtype=torch.float)\n",
    "        return user_id, item_id, genre, rating\n",
    "\n",
    "# 创建数据加载器\n",
    "train_dataset = MovieLensDataset(train)\n",
    "test_dataset = MovieLensDataset(test)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04e57dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.8598\n",
      "Epoch 2/20, Loss: 0.9601\n",
      "Epoch 3/20, Loss: 0.8334\n",
      "Epoch 4/20, Loss: 0.8266\n",
      "Epoch 5/20, Loss: 0.8306\n",
      "Epoch 6/20, Loss: 0.8440\n",
      "Epoch 7/20, Loss: 0.9627\n",
      "Epoch 8/20, Loss: 0.8207\n",
      "Epoch 9/20, Loss: 0.9529\n",
      "Epoch 10/20, Loss: 0.9054\n",
      "Epoch 11/20, Loss: 0.6285\n",
      "Epoch 12/20, Loss: 0.6978\n",
      "Epoch 13/20, Loss: 0.6394\n",
      "Epoch 14/20, Loss: 1.0055\n",
      "Epoch 15/20, Loss: 0.7117\n",
      "Epoch 16/20, Loss: 0.8786\n",
      "Epoch 17/20, Loss: 0.6169\n",
      "Epoch 18/20, Loss: 0.7495\n",
      "Epoch 19/20, Loss: 0.5488\n",
      "Epoch 20/20, Loss: 0.8523\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 超参数\n",
    "DNN_USER_DIM = 32\n",
    "DNN_ITEM_DIM = 32\n",
    "DNN_HIDDEN_UNITS = [64, 32]\n",
    "DNN_OPTIMIZER_LR = 0.001\n",
    "LINEAR_OPTIMIZER_LR = 0.01\n",
    "DNN_DROPOUT = 0.5\n",
    "DNN_BATCH_NORM = True\n",
    "STEPS = 20\n",
    "\n",
    "# 初始化模型\n",
    "model = WideAndDeepModel(DNN_USER_DIM, DNN_ITEM_DIM, len(genres_encoder.classes_), DNN_HIDDEN_UNITS)\n",
    "optimizer = optim.Adam(model.parameters(), lr=DNN_OPTIMIZER_LR)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(STEPS):\n",
    "    model.train()\n",
    "    for user_ids, item_ids, genres, ratings in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_ids, item_ids, genres)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{STEPS}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ae51c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    \"\"\"计算 RMSE（均方根误差）\"\"\"\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    \"\"\"计算 MAE（平均绝对误差）\"\"\"\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def calculate_ndcg(y_true, y_pred, k=10):\n",
    "    \"\"\"计算 NDCG@K（归一化折损累积增益）\"\"\"\n",
    "    def dcg_score(y_true, y_pred, k):\n",
    "        order = np.argsort(y_pred)[::-1]\n",
    "        y_true = np.take(y_true, order[:k])\n",
    "        gain = 2 ** y_true - 1\n",
    "        discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "        return np.sum(gain / discounts)\n",
    "    \n",
    "    dcg = dcg_score(y_true, y_pred, k)\n",
    "    idcg = dcg_score(y_true, y_true, k)\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "def calculate_precision_at_k(y_true, y_pred, k=10):\n",
    "    \"\"\"计算 Precision@K\"\"\"\n",
    "    order = np.argsort(y_pred)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    return np.sum(y_true) / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cc5121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.022181516793539\n",
      "MAE: 0.8009374121320247\n",
      "NDCG@10: 0.8706325607206493\n",
      "Precision@10: 4.6\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "model.eval()\n",
    "pred_ratings = []\n",
    "true_ratings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for user_ids, item_ids, genres, ratings in test_loader:\n",
    "        predictions = model(user_ids, item_ids, genres)\n",
    "        pred_ratings.extend(predictions.tolist())\n",
    "        true_ratings.extend(ratings.tolist())\n",
    "\n",
    "# 计算评估指标\n",
    "rmse_value = calculate_rmse(true_ratings, pred_ratings)\n",
    "mae_value = calculate_mae(true_ratings, pred_ratings)\n",
    "ndcg_value = calculate_ndcg(true_ratings, pred_ratings, k=10)\n",
    "precision_value = calculate_precision_at_k(true_ratings, pred_ratings, k=10)\n",
    "\n",
    "print(\"RMSE:\", rmse_value)\n",
    "print(\"MAE:\", mae_value)\n",
    "print(\"NDCG@10:\", ndcg_value)\n",
    "print(\"Precision@10:\", precision_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a77b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5207d63a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recommendations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m电影ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovie\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 预测评分: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrating\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, 新推荐\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m analyze_recommendations(\u001b[38;5;241m196\u001b[39m, \u001b[43mrecommendations\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recommendations' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b78279e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
